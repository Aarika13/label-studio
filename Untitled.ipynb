{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f936b43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def create_image_urls(directory):\n",
    "    \"\"\"\n",
    "    Generate image URLs for all image files in the specified directory\n",
    "    \"\"\"\n",
    "    image_urls = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.lower().endswith(('.jpg', '.jpeg', '.png', '.gif', '.bmp', '.svg')):\n",
    "            image_urls.append(f'http://localhost:8080/{filename}')\n",
    "    return image_urls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "592ad0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['http://localhost:8080/51fKgIgEv5L.jpg', 'http://localhost:8080/63a085d8d4fdce0328d9226c_Screen Shot 2022-12-19 at 10.38.35 AM.png', 'http://localhost:8080/8150716b94bdf1e235300c5f3036f383-invoice-template-pdf-grey-1.png', 'http://localhost:8080/18102022_TAX_INVOICE_IN00012_ClearTax-11-1024x1012.jpg']\n"
     ]
    }
   ],
   "source": [
    "image_directory = \"/home/aarika/Desktop/New_OCR/myfiles/sample/\"\n",
    "urls = create_image_urls(image_directory)\n",
    "print(urls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ba651bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 101\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Image\u001b[38;5;241m.\u001b[39mopen(f\u001b[38;5;241m.\u001b[39mabsolute()) \u001b[38;5;28;01mas\u001b[39;00m image:\n\u001b[1;32m    100\u001b[0m         tesseract_output \u001b[38;5;241m=\u001b[39m pytesseract\u001b[38;5;241m.\u001b[39mimage_to_data(image, output_type\u001b[38;5;241m=\u001b[39mpytesseract\u001b[38;5;241m.\u001b[39mOutput\u001b[38;5;241m.\u001b[39mDICT)\n\u001b[0;32m--> 101\u001b[0m         task \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_ls\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtesseract_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mper_level\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mblock_num\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m         tasks\u001b[38;5;241m.\u001b[39mappend(task)\n\u001b[1;32m    104\u001b[0m \u001b[38;5;66;03m# create a file to import into Label Studio\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[13], line 89\u001b[0m, in \u001b[0;36mconvert_to_ls\u001b[0;34m(image, tesseract_output, per_level)\u001b[0m\n\u001b[1;32m     84\u001b[0m         results\u001b[38;5;241m.\u001b[39mextend([bbox_result, transcription_result])\n\u001b[1;32m     85\u001b[0m         all_scores\u001b[38;5;241m.\u001b[39mappend(score)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m: {\n\u001b[0;32m---> 89\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mocr\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mcreate_image_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m     },\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredictions\u001b[39m\u001b[38;5;124m'\u001b[39m: [{\n\u001b[1;32m     92\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m'\u001b[39m: results,\n\u001b[1;32m     93\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28msum\u001b[39m(all_scores) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(all_scores) \u001b[38;5;28;01mif\u001b[39;00m all_scores \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     94\u001b[0m     }]\n\u001b[1;32m     95\u001b[0m }\n",
      "Cell \u001b[0;32mIn[13], line 29\u001b[0m, in \u001b[0;36mcreate_image_url\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m     26\u001b[0m filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(filepath)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# print(\"test == \",filename)\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# return f'http://localhost:8080/{filename[0]}'\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mfilename\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m()\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpeg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.gif\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.bmp\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.svg\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp://localhost:8080/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from uuid import uuid4\n",
    "import requests\n",
    "from django.conf import settings\n",
    "LEVELS = {\n",
    "    'page_num': 1,\n",
    "    'block_num': 2,\n",
    "    'par_num': 3,\n",
    "    'line_num': 4,\n",
    "    'word_num': 5\n",
    "}\n",
    "# LABEL_STUDIO_LOCAL_FILES_SERVING_ENABLED=True\n",
    "# LABEL_STUDIO_LOCAL_FILES_DOCUMENT_ROOT='/home/aarika/.local/share/label-studio/media/myfiles/dataset1/'\n",
    "# LOCAL_FILES_DOCUMENT_ROOT = r'/home/aarika/New_OCR/myfiles/dataset1/'\n",
    "# LABEL_STUDIO_LOCAL_FILES_DOCUMENT_ROOT = True\n",
    "# LABEL_STUDIO_LOCAL_FILES_SERVING_ENABLED = True\n",
    "# LOCAL_FILES_SERVING_ENABLED = True\n",
    "# LABEL_STUDIO_BASE_DATA_DIR = r'/home/aarika/DesktopNew_OCR/image/'\n",
    "def create_image_url(filepath):\n",
    "    filepath = r\"/home/aarika/Desktop/New_OCR/myfiles/sample/\"\n",
    "    # print(\"test == \", filepath)\n",
    "    filename = os.listdir(filepath)\n",
    "    # print(\"test == \",filename)\n",
    "    # return f'http://localhost:8080/{filename[0]}'\n",
    "    if filename.lower().endswith(('.jpg', '.jpeg', '.png', '.gif', '.bmp', '.svg')):\n",
    "        return f'http://localhost:8080/{filename}'\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    \n",
    "#     image_urls = []\n",
    "#     for filename in os.listdir(directory):\n",
    "#         if filename.lower().endswith(('.jpg', '.jpeg', '.png', '.gif', '.bmp', '.svg')):\n",
    "#             image_urls.append(f'http://localhost:8080/{filename}')\n",
    "#     return image_urls\n",
    "\n",
    "\n",
    "def convert_to_ls(image, tesseract_output, per_level='block_num'):\n",
    "    \"\"\"\n",
    "    :param image: PIL image object\n",
    "    :param tesseract_output: the output from tesseract\n",
    "    :param per_level: control the granularity of bboxes from tesseract\n",
    "    :return: tasks.json ready to be imported into Label Studio with \"Optical Character Recognition\" template\n",
    "    \"\"\"\n",
    "    image_width, image_height = image.size\n",
    "    per_level_idx = LEVELS[per_level]\n",
    "    results = []\n",
    "    all_scores = []\n",
    "    for i, level_idx in enumerate(tesseract_output['level']):\n",
    "        if level_idx == per_level_idx:\n",
    "            bbox = {\n",
    "                'x': 100 * tesseract_output['left'][i] / image_width,\n",
    "                'y': 100 * tesseract_output['top'][i] / image_height,\n",
    "                'width': 100 * tesseract_output['width'][i] / image_width,\n",
    "                'height': 100 * tesseract_output['height'][i] / image_height,\n",
    "                'rotation': 0\n",
    "            }\n",
    "\n",
    "            words, confidences = [], []\n",
    "            for j, curr_id in enumerate(tesseract_output[per_level]):\n",
    "                if curr_id != tesseract_output[per_level][i]:\n",
    "                    continue\n",
    "                word = tesseract_output['text'][j]\n",
    "                confidence = tesseract_output['conf'][j]\n",
    "                words.append(word)\n",
    "                if confidence != '-1':\n",
    "                    confidences.append(float(confidence / 100.))\n",
    "\n",
    "            text = ' '.join(words).strip()\n",
    "            if not text:\n",
    "                continue\n",
    "            region_id = str(uuid4())[:10]\n",
    "            score = sum(confidences) / len(confidences) if confidences else 0\n",
    "            bbox_result = {\n",
    "                'id': region_id, 'from_name': 'bbox', 'to_name': 'image', 'type': 'rectangle',\n",
    "                'value': bbox}\n",
    "            transcription_result = {\n",
    "                'id': region_id, 'from_name': 'transcription', 'to_name': 'image', 'type': 'textarea',\n",
    "                'value': dict(text=[text], **bbox), 'score': score}\n",
    "            results.extend([bbox_result, transcription_result])\n",
    "            all_scores.append(score)\n",
    "\n",
    "    return {\n",
    "        'data': {\n",
    "            'ocr': create_image_url(image.filename)\n",
    "        },\n",
    "        'predictions': [{\n",
    "            'result': results,\n",
    "            'score': sum(all_scores) / len(all_scores) if all_scores else 0\n",
    "        }]\n",
    "    }        \n",
    "tasks = []\n",
    "# collect the receipt images from the image directory\n",
    "for f in Path('image').glob('*.png'):\n",
    "    with Image.open(f.absolute()) as image:\n",
    "        tesseract_output = pytesseract.image_to_data(image, output_type=pytesseract.Output.DICT)\n",
    "        task = convert_to_ls(image, tesseract_output, per_level='block_num')\n",
    "        tasks.append(task)\n",
    "\n",
    "# create a file to import into Label Studio\n",
    "with open('ocr_tasks.json', mode='w') as f:\n",
    "    json.dump(tasks, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15d0b946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install django"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0cb599b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from uuid import uuid4\n",
    "import requests\n",
    "from django.conf import settings\n",
    "\n",
    "# Tesseract output levels for the level of detail for the bounding boxes\n",
    "LEVELS = {\n",
    "    'page_num': 1,\n",
    "    'block_num': 2,\n",
    "    'par_num': 3,\n",
    "    'line_num': 4,\n",
    "    'word_num': 5\n",
    "}\n",
    "\n",
    "LABEL_STUDIO_LOCAL_FILES_SERVING_ENABLED = True\n",
    "LOCAL_FILES_DOCUMENT_ROOT = r'/home/aarika/New_OCR/myfiles/dataset1/'\n",
    "LOCAL_FILES_SERVING_ENABLED = True\n",
    "\n",
    "\n",
    "def create_image_url(filename):\n",
    "    return f'http://localhost:8080/{filename}'\n",
    "\n",
    "\n",
    "def convert_to_ls(image, tesseract_output, per_level='block_num'):\n",
    "    image_width, image_height = image.size\n",
    "    per_level_idx = LEVELS[per_level]\n",
    "    results = []\n",
    "    all_scores = []\n",
    "\n",
    "    for i, level_idx in enumerate(tesseract_output['level']):\n",
    "        if level_idx == per_level_idx:\n",
    "            bbox = {\n",
    "                'x': 100 * tesseract_output['left'][i] / image_width,\n",
    "                'y': 100 * tesseract_output['top'][i] / image_height,\n",
    "                'width': 100 * tesseract_output['width'][i] / image_width,\n",
    "                'height': 100 * tesseract_output['height'][i] / image_height,\n",
    "                'rotation': 0\n",
    "            }\n",
    "\n",
    "            words, confidences = [], []\n",
    "            for j, curr_id in enumerate(tesseract_output[per_level]):\n",
    "                if curr_id != tesseract_output[per_level][i]:\n",
    "                    continue\n",
    "                word = tesseract_output['text'][j]\n",
    "                confidence = tesseract_output['conf'][j]\n",
    "                words.append(word)\n",
    "                if confidence != '-1':\n",
    "                    confidences.append(float(confidence) / 100.0)\n",
    "\n",
    "            text = ' '.join(words).strip()\n",
    "            if not text:\n",
    "                continue\n",
    "            region_id = str(uuid4())[:10]\n",
    "            score = sum(confidences) / len(confidences) if confidences else 0\n",
    "\n",
    "            bbox_result = {\n",
    "                'id': region_id,\n",
    "                'from_name': 'bbox',\n",
    "                'to_name': 'image',\n",
    "                'type': 'rectangle',\n",
    "                'value': bbox\n",
    "            }\n",
    "\n",
    "            transcription_result = {\n",
    "                'id': region_id,\n",
    "                'from_name': 'transcription',\n",
    "                'to_name': 'image',\n",
    "                'type': 'textarea',\n",
    "                'value': dict(text=[text], **bbox),\n",
    "                'score': score\n",
    "            }\n",
    "\n",
    "            results.extend([bbox_result, transcription_result])\n",
    "            all_scores.append(score)\n",
    "\n",
    "    return {\n",
    "        'data': {\n",
    "            'ocr': create_image_url(image.filename)\n",
    "        },\n",
    "        'predictions': [{\n",
    "            'result': results,\n",
    "            'score': sum(all_scores) / len(all_scores) if all_scores else 0\n",
    "        }]\n",
    "    }\n",
    "\n",
    "\n",
    "tasks = []\n",
    "\n",
    "# Collect the receipt images from the image directory\n",
    "for f in Path('image').glob('*.png'):\n",
    "    with Image.open(f.absolute()) as image:\n",
    "        tesseract_output = pytesseract.image_to_data(image, output_type=pytesseract.Output.DICT)\n",
    "        task = convert_to_ls(image, tesseract_output, per_level='block_num')\n",
    "        tasks.append(task)\n",
    "\n",
    "with open('ocr_tasks.json', mode='w') as f:\n",
    "    json.dump(tasks, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b96f646a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['http://localhost:8080/51fKgIgEv5L.jpg', 'http://localhost:8080/63a085d8d4fdce0328d9226c_Screen Shot 2022-12-19 at 10.38.35 AM.png', 'http://localhost:8080/8150716b94bdf1e235300c5f3036f383-invoice-template-pdf-grey-1.png', 'http://localhost:8080/18102022_TAX_INVOICE_IN00012_ClearTax-11-1024x1012.jpg']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def create_image_url(filepath):\n",
    "    \"\"\"\n",
    "    Label Studio requires image URLs, so this defines the mapping from filesystem to URLs\n",
    "    if you use ./serve_local_files.sh <my-images-dir>, the image URLs are localhost:8081/filename.png\n",
    "    Otherwise you can build links like /data/upload/filename.png to refer to the files\n",
    "    \"\"\"\n",
    "    filename = os.path.basename(filepath)\n",
    "    return f'http://localhost:8080/{filename}'\n",
    "\n",
    "folder_path = '/home/aarika/Desktop/New_OCR/myfiles/sample/'  # Specify the path to the folder containing the images\n",
    "\n",
    "image_urls = []\n",
    "for filename in os.listdir(folder_path):\n",
    "    filepath = os.path.join(folder_path, filename)\n",
    "    if os.path.isfile(filepath):\n",
    "        image_url = create_image_url(filepath)\n",
    "        image_urls.append(image_url)\n",
    "\n",
    "print(image_urls)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d787a7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Step 1: Prepare the dataset\n",
    "invoice_directory = '/home/aarika/Desktop/New_OCR/data/dataset1/'\n",
    "labels = ['label1', 'label2', 'label3']  # Define your labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50a10ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load and preprocess the dataset\n",
    "data = []\n",
    "target = []\n",
    "\n",
    "for filename in os.listdir(invoice_directory):\n",
    "    if filename.endswith('.txt'):\n",
    "        with open(os.path.join(invoice_directory, filename), 'r') as file:\n",
    "            content = file.read()\n",
    "            data.append(content)\n",
    "            label = get_label_from_filename(filename)  # Implement this function to extract the label from the filename\n",
    "            target.append(label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16efe8d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Step 3: Split the dataset into training and testing sets\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m----> 4\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_split.py:2562\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2559\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[1;32m   2561\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m-> 2562\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2563\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\n\u001b[1;32m   2564\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2566\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m   2567\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_split.py:2236\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2233\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[1;32m   2235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2236\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2237\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2238\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2239\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[1;32m   2240\u001b[0m     )\n\u001b[1;32m   2242\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "# Step 3: Split the dataset into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c31d32f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Step 4: Vectorize the text data\u001b[39;00m\n\u001b[1;32m      2\u001b[0m vectorizer \u001b[38;5;241m=\u001b[39m TfidfVectorizer()\n\u001b[0;32m----> 3\u001b[0m X_train_vectorized \u001b[38;5;241m=\u001b[39m vectorizer\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mX_train\u001b[49m)\n\u001b[1;32m      4\u001b[0m X_test_vectorized \u001b[38;5;241m=\u001b[39m vectorizer\u001b[38;5;241m.\u001b[39mtransform(X_test)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Step 5: Train the text classification model\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Step 4: Vectorize the text data\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "# Step 5: Train the text classification model\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Step 6: Make predictions\n",
    "y_pred = classifier.predict(X_test_vectorized)\n",
    "\n",
    "# Step 7: Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Step 8: Print the evaluation metrics\n",
    "print('Accuracy:', accuracy)\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "print('F1 Score:', f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6bff58c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_label_from_filename' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m             text \u001b[38;5;241m=\u001b[39m pytesseract\u001b[38;5;241m.\u001b[39mimage_to_string(image)\n\u001b[1;32m     22\u001b[0m             data\u001b[38;5;241m.\u001b[39mappend(text)\n\u001b[0;32m---> 23\u001b[0m             label \u001b[38;5;241m=\u001b[39m \u001b[43mget_label_from_filename\u001b[49m(filename)  \u001b[38;5;66;03m# Implement this function to extract the label from the filename\u001b[39;00m\n\u001b[1;32m     24\u001b[0m             target\u001b[38;5;241m.\u001b[39mappend(label)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Step 3: Split the dataset into training and testing sets\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_label_from_filename' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "# Step 1: Prepare the dataset\n",
    "invoice_directory = '/home/aarika/Desktop/New_OCR/data/dataset1/'\n",
    "labels = ['label1', 'label2', 'label3']  # Define your labels\n",
    "\n",
    "# Step 2: Load and preprocess the dataset\n",
    "data = []\n",
    "target = []\n",
    "\n",
    "for filename in os.listdir(invoice_directory):\n",
    "    if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "        image_path = os.path.join(invoice_directory, filename)\n",
    "        with Image.open(image_path) as image:\n",
    "            text = pytesseract.image_to_string(image)\n",
    "            data.append(text)\n",
    "            label = get_label_from_filename(filename)  # Implement this function to extract the label from the filename\n",
    "            target.append(label)\n",
    "\n",
    "# Step 3: Split the dataset into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 4: Vectorize the text data\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "# Step 5: Train the text classification model\n",
    "classifier = LinearSVC()\n",
    "classifier.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Step 6: Make predictions\n",
    "y_pred = classifier.predict(X_test_vectorized)\n",
    "\n",
    "# Step 7: Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Step 8: Print the evaluation metrics\n",
    "print('Accuracy:', accuracy)\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "print('F1 Score:', f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "025323d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 17\u001b[0m\n\u001b[1;32m     13\u001b[0m ner_labels \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m annotated_data:\n\u001b[0;32m---> 17\u001b[0m     text_samples\u001b[38;5;241m.\u001b[39mappend(\u001b[43msample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     18\u001b[0m     ner_labels\u001b[38;5;241m.\u001b[39mappend(sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mner_label\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Step 3: Split the dataset into training and testing sets\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "\n",
    "# Step 1: Load the annotated data\n",
    "with open(r'/home/aarika/Desktop/OCR/annotations.json', 'r') as file:\n",
    "    annotated_data = json.load(file)\n",
    "\n",
    "# Step 2: Prepare the dataset\n",
    "text_samples = []\n",
    "ner_labels = []\n",
    "\n",
    "for sample in annotated_data:\n",
    "\n",
    "    text_samples.append(sample['text'])\n",
    "    ner_labels.append(sample['ner_label'])\n",
    "\n",
    "# Step 3: Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(text_samples, ner_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 4: Feature extraction - TF-IDF vectorization\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "# Step 5: Encode the NER labels\n",
    "# Implement your own encoding method suitable for your NER labels\n",
    "\n",
    "# Step 6: Train the text classification model\n",
    "classifier = SVC()\n",
    "classifier.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Step 7: Make predictions\n",
    "y_pred = classifier.predict(X_test_vectorized)\n",
    "\n",
    "# Step 8: Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Step 9: Print the evaluation metrics\n",
    "print('Accuracy:', accuracy)\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "print('F1 Score:', f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd12622",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *  \n",
    "  \n",
    "top = Tk()  \n",
    "  \n",
    "top.geometry(\"400x250\")  \n",
    "  \n",
    "#creating label  \n",
    "uname = Label(top, text = \"Username\").place(x = 30,y = 50)  \n",
    "  \n",
    "#creating label  \n",
    "password = Label(top, text = \"Password\").place(x = 30, y = 90)  \n",
    "  \n",
    "  \n",
    "sbmitbtn = Button(top, text = \"Submit\",activebackground = \"pink\", activeforeground = \"blue\").place(x = 30, y = 120)  \n",
    "  \n",
    "e1 = Entry(top,width = 20).place(x = 100, y = 50)  \n",
    "  \n",
    "  \n",
    "e2 = Entry(top, width = 20).place(x = 100, y = 90)  \n",
    "  \n",
    "  \n",
    "top.mainloop()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22806c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4727820e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "# Open the image\n",
    "image_path = '/home/aarika/Desktop/New_OCR/data/upload/abc.jpg'  # Replace with your image path\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Create a drawing object\n",
    "draw = ImageDraw.Draw(image)\n",
    "\n",
    "# Define the label text and font\n",
    "label_text = 'Label'\n",
    "font = ImageFont.truetype('arial.ttf', 16)  # Replace with your desired font and size\n",
    "\n",
    "# Define the label position (top-left coordinates)\n",
    "label_position = (10, 10)  # Adjust as per your preference\n",
    "\n",
    "# Define the label color\n",
    "label_color = (255, 0, 0)  # Red color (RGB format)\n",
    "\n",
    "# Add the label to the image\n",
    "draw.text(label_position, label_text, font=font, fill=label_color)\n",
    "\n",
    "# Save the image with the label\n",
    "image_with_label_path = 'image_with_label.jpg'  # Replace with the desired output path\n",
    "image.save(image_with_label_path)\n",
    "\n",
    "# Display the image\n",
    "image.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce2d09e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
